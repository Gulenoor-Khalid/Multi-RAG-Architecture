# ğŸ¤– RAG Multi-LLM System (Quantized 8B Models)

![GitHub Repo stars](https://img.shields.io/github/stars/Kietnehi/RAG?style=social)
![GitHub forks](https://img.shields.io/github/forks/Kietnehi/RAG?style=social)
![GitHub issues](https://img.shields.io/github/issues/Kietnehi/RAG)
![GitHub license](https://img.shields.io/github/license/Kietnehi/RAG)
![Docker](https://img.shields.io/badge/Docker-Supported-blue)
![Python](https://img.shields.io/badge/Python-3.9%2B-brightgreen)

> ğŸš€ **RAG Multi-LLM System** lÃ  má»™t há»‡ thá»‘ng **Retrieval-Augmented Generation (RAG)** hoÃ n chá»‰nh, há»— trá»£ **nhiá»u mÃ´ hÃ¬nh LLM quantized (4-bit / 8-bit)**, cÃ³ giao diá»‡n web, vector database vÃ  triá»ƒn khai dá»… dÃ ng báº±ng Docker.

> ğŸ”— **[GitHub Repository chÃ­nh thá»©c](https://github.com/Kietnehi/RAG)**


---

<p align="center">
  <img src="output.gif" width="100%" alt="Intro GIF" />
</p>


## ğŸ“Œ Giá»›i thiá»‡u dá»± Ã¡n

Dá»± Ã¡n **RAG Multi-LLM System** Ä‘Æ°á»£c xÃ¢y dá»±ng nháº±m má»¥c tiÃªu:

- ğŸ§  NghiÃªn cá»©u & triá»ƒn khai **Retrieval-Augmented Generation (RAG)** trong thá»±c táº¿
- âš¡ Cháº¡y **LLM 7Bâ€“8B** trÃªn mÃ¡y cáº¥u hÃ¬nh háº¡n cháº¿ báº±ng **quantization**
- ğŸŒ Cung cáº¥p **Web UI trá»±c quan** cho ngÆ°á»i dÃ¹ng cuá»‘i
- ğŸ³ Há»— trá»£ **Docker / GPU / CPU**
- ğŸ“š PhÃ¹ há»£p cho **educational, research, demo & portfolio**

---

## ğŸ§  AI â€“ Deep Learning â€“ RAG Overview

<table align="center">
  <tr>
    <td align="center" width="50%">
      <img src="image/readme/AI.jpg" width="100%" alt="AI Overview"><br>
      <b>Artificial Intelligence (AI)</b><br>
      <sub>Tá»•ng quan trÃ­ tuá»‡ nhÃ¢n táº¡o</sub>
    </td>
    <td align="center" width="50%">
      <img src="image/readme/deeplearning.jpg" width="100%" alt="Deep Learning"><br>
      <b>Deep Learning</b><br>
      <sub>Ná»n táº£ng cho LLM</sub>
    </td>
  </tr>
  <tr>
    <td align="center">
      <img src="image/readme/docx.jpg" width="100%" alt="RAG Documents"><br>
      <b>RAG Input Documents</b><br>
      <sub>PDF, DOCX, TXT</sub>
    </td>
    <td align="center">
      <img src="image/readme/rag_pipeline.jpg" width="100%" alt="RAG Pipeline"><br>
      <b>RAG Pipeline</b><br>
      <sub>Retrieve â†’ Context â†’ Generate</sub>
    </td>
  </tr>
</table>

---
## ğŸ³ Triá»ƒn khai Docker & Demo Giao Diá»‡n Web

> Minh há»a cÃ¡c Docker containers, Docker images vÃ  giao diá»‡n web cá»§a há»‡ thá»‘ng RAG Multi-LLM

### ğŸ“¦ CÃ¡c Docker Containers Ä‘ang cháº¡y

<p align="center">
  <img src="image/docker_container.png" width="90%" alt="Docker Containers">
</p>

<sub align="center">
Danh sÃ¡ch cÃ¡c container: frontend, backend (FastAPI), vector database
</sub>

---

### ğŸ§± Docker Images

#### ğŸ”¹ Docker Image â€“ Frontend

<p align="center">
  <img src="image/docker_image_frontend.png" width="80%" alt="Docker Image Frontend">
</p>

<sub align="center">
Image cho giao diá»‡n Web UI (HTML / CSS / JavaScript + Nginx)
</sub>

#### ğŸ”¹ Docker Image â€“ Backend

<p align="center">
  <img src="image/docker_image_backend.png" width="80%" alt="Docker Image Backend">
</p>

<sub align="center">
Image cho Backend FastAPI + LLM + RAG Engine
</sub>

---

### ğŸŒ Giao diá»‡n Web (Web UI)

<p align="center">
  <img src="image/frontend.png" width="90%" alt="Web UI Chat">
</p>

<sub align="center">
Giao diá»‡n chat RAG: upload tÃ i liá»‡u, chá»n mÃ´ hÃ¬nh, streaming cÃ¢u tráº£ lá»i
</sub>

**Demo Run**

<p align="center">
  <img src="image/demo_run_rag.png" width="90%" alt="Demo Run RAG">
</p>

<sub align="center">
áº¢nh minh há»a quÃ¡ trÃ¬nh cháº¡y RAG (upload tÃ i liá»‡u vÃ  pháº£n há»“i tá»« model).
</sub>

---

## âœ¨ TÃ­nh nÄƒng

- ğŸ§  **Há»— trá»£ nhiá»u LLM models 8B** (quantized vá»›i 4-bit/8-bit)
  - Meta Llama 2 7B
  - Mistral 7B Instruct
  - Google Gemma 7B
  - Microsoft Phi-2
  - TinyLlama 1.1B

- ğŸ“š **RAG vá»›i Vector Database**
  - ChromaDB cho vector storage
  - Sentence transformers cho embeddings
  - Há»— trá»£ PDF, DOCX, TXT

- ğŸ¨ **Web Interface hiá»‡n Ä‘áº¡i**
  - Chat interface vá»›i streaming
  - Upload vÃ  quáº£n lÃ½ documents
  - Switch giá»¯a cÃ¡c models
  - Äiá»u chá»‰nh temperature, max tokens

- ğŸ³ **Docker support**
  - Docker Compose cho deployment dá»… dÃ ng
  - GPU support cho inference nhanh
  - Persistent storage cho documents

## ğŸ—ï¸ Kiáº¿n trÃºc

```
RAG MINI/
â”œâ”€â”€ backend/                 # FastAPI backend
â”‚   â””â”€â”€ app/
â”‚       â”œâ”€â”€ main.py         # API endpoints
â”‚       â”œâ”€â”€ models/
â”‚       â”‚   â”œâ”€â”€ llm_manager.py    # Quáº£n lÃ½ LLM models
â”‚       â”‚   â””â”€â”€ rag_engine.py     # RAG logic
â”‚       â””â”€â”€ utils/
â”‚           â””â”€â”€ document_processor.py
â”œâ”€â”€ frontend/               # Web UI
â”‚   â”œâ”€â”€ index.html
â”‚   â”œâ”€â”€ style.css
â”‚   â””â”€â”€ script.js
â”œâ”€â”€ Dockerfile             # Backend container
â”œâ”€â”€ Dockerfile.frontend    # Frontend container
â”œâ”€â”€ docker-compose.yml     # Orchestration
â”œâ”€â”€ nginx.conf            # Nginx config
â””â”€â”€ requirements.txt      # Python dependencies
```

## ğŸš€ CÃ i Ä‘áº·t vÃ  Cháº¡y

### YÃªu cáº§u

- Docker & Docker Compose
- NVIDIA GPU (khuyáº¿n nghá»‹, nhÆ°ng cÃ³ thá»ƒ cháº¡y trÃªn CPU)
- 8GB RAM trá»Ÿ lÃªn
- 10GB disk space cho models

### CÃ¡ch 1: Docker Compose (Khuyáº¿n nghá»‹)

1. **Clone hoáº·c táº£i project**

2. **Cáº¥u hÃ¬nh mÃ´i trÆ°á»ng** (optional)
```bash
cp .env.example .env
# Edit .env Ä‘á»ƒ thay Ä‘á»•i model máº·c Ä‘á»‹nh vÃ  settings
```

3. **Build vÃ  cháº¡y**
```bash
docker-compose up --build
```

4. **Truy cáº­p á»©ng dá»¥ng**
- Frontend: http://localhost
- Backend API: http://localhost:8000
- API Docs: http://localhost:8000/docs

### CÃ¡ch 2: Local Development

1. **CÃ i Ä‘áº·t dependencies**
```bash
pip install -r requirements.txt
```

2. **Táº¡o file .env**
```bash
cp .env.example .env
```

3. **Cháº¡y backend**
```bash
cd backend
uvicorn app.main:app --host 0.0.0.0 --port 8000 --reload
```

4. **Cháº¡y frontend**
```bash
# Má»Ÿ frontend/index.html trong browser
# Hoáº·c dÃ¹ng simple HTTP server:
cd frontend
python -m http.server 3000
```

## ğŸ® Sá»­ dá»¥ng

### 1. Upload Documents

1. Click vÃ o **"ğŸ“ Upload Documents"** trong sidebar
2. Chá»n file (PDF, DOCX, TXT)
3. Click **Upload**
4. Documents sáº½ Ä‘Æ°á»£c xá»­ lÃ½ vÃ  lÆ°u vÃ o vector database

### 2. Chat vá»›i RAG

1. Nháº­p cÃ¢u há»i vÃ o chat input
2. Báº­t **"Sá»­ dá»¥ng RAG"** Ä‘á»ƒ query tá»« documents
3. Táº¯t RAG Ä‘á»ƒ chat trá»±c tiáº¿p vá»›i LLM
4. Click **Gá»­i** hoáº·c nháº¥n Enter

### 3. Switch Models

1. Chá»n model tá»« dropdown **"Model"**
2. Click **"Load Model"**
3. Äá»£i model load (cÃ³ thá»ƒ máº¥t 1-2 phÃºt)

### 4. Äiá»u chá»‰nh Parameters

- **Temperature**: 0-1 (creativity)
- **Max Tokens**: 128-2048 (response length)

## ğŸ”§ Cáº¥u hÃ¬nh

### Environment Variables (.env)

```env
# Model Configuration
MODEL_NAME=TinyLlama/TinyLlama-1.1B-Chat-v1.0
LOAD_IN_8BIT=true
LOAD_IN_4BIT=false

# Generation Settings
MAX_NEW_TOKENS=512
TEMPERATURE=0.7

# Vector DB Settings
EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2
CHUNK_SIZE=500
CHUNK_OVERLAP=50
```

### Chá»n Model khÃ¡c

Sá»­a `MODEL_NAME` trong `.env`:

```env
# Llama 2 7B (yÃªu cáº§u HuggingFace token)
MODEL_NAME=meta-llama/Llama-2-7b-chat-hf

# Mistral 7B
MODEL_NAME=mistralai/Mistral-7B-Instruct-v0.2

# Gemma 7B (yÃªu cáº§u Google token)
MODEL_NAME=google/gemma-7b-it

# Phi-2 (nhá», nhanh)
MODEL_NAME=microsoft/phi-2

# TinyLlama (nhá» nháº¥t, cho testing)
MODEL_NAME=TinyLlama/TinyLlama-1.1B-Chat-v1.0
```

### Quantization Options

```env
# 8-bit quantization (tiáº¿t kiá»‡m ~50% VRAM)
LOAD_IN_8BIT=true
LOAD_IN_4BIT=false

# 4-bit quantization (tiáº¿t kiá»‡m ~75% VRAM)
LOAD_IN_8BIT=false
LOAD_IN_4BIT=true
```

## ğŸ“Š API Endpoints

### Health Check
```bash
GET /health
```

### List Models
```bash
GET /models
```

### Load Model
```bash
POST /models/load?model_name=<model_name>
```

### Upload Document
```bash
POST /upload
Content-Type: multipart/form-data
```

### Query (RAG)
```bash
POST /query
Content-Type: application/json

{
  "query": "Your question here",
  "use_rag": true,
  "max_tokens": 512,
  "temperature": 0.7
}
```

### Clear Documents
```bash
DELETE /documents
```

## ğŸ› Troubleshooting

### Model khÃ´ng load Ä‘Æ°á»£c

1. Kiá»ƒm tra RAM/VRAM Ä‘á»§ khÃ´ng
2. Thá»­ model nhá» hÆ¡n (TinyLlama)
3. Enable quantization (8-bit hoáº·c 4-bit)

### Out of Memory

1. TÄƒng Docker memory limit
2. Sá»­ dá»¥ng 4-bit quantization
3. Chá»n model nhá» hÆ¡n

### Docker khÃ´ng start

```bash
# Xem logs
docker-compose logs -f

# Restart
docker-compose down
docker-compose up --build
```

### GPU khÃ´ng Ä‘Æ°á»£c detect

1. CÃ i Ä‘áº·t NVIDIA Docker runtime
2. Kiá»ƒm tra: `docker run --gpus all nvidia/cuda:11.8.0-base-ubuntu22.04 nvidia-smi`
3. Náº¿u khÃ´ng cÃ³ GPU, xÃ³a pháº§n `deploy.resources` trong docker-compose.yml

## ğŸ¯ Performance Tips

1. **Sá»­ dá»¥ng GPU**: Nhanh hÆ¡n 10-20x so vá»›i CPU
2. **Quantization**: Giáº£m VRAM, tÄƒng tá»‘c Ä‘á»™
3. **Cache models**: Models Ä‘Æ°á»£c cache sau láº§n Ä‘áº§u
4. **Chunking**: Adjust `CHUNK_SIZE` phÃ¹ há»£p vá»›i documents
## ğŸ“ TODO / Improvements

- [ ] ThÃªm **authentication**
- [ ] Multi-user support
- [ ] Conversation history
- [ ] Advanced RAG strategies (HyDE, Multi-query)
- [ ] Model comparison mode
- [ ] Export chat history
- [ ] Support thÃªm file formats (CSV, Excel, etc.)

---

## ğŸ¤ Contributing

ChÃºng tÃ´i hoan nghÃªnh má»i Ä‘Ã³ng gÃ³p!  
Vui lÃ²ng táº¡o **issue** hoáº·c **pull request** trÃªn GitHub.

---

## ğŸ“„ License

MIT License

---

## ğŸ™ Credits

- FastAPI  
- Transformers (HuggingFace)  
- LangChain  
- ChromaDB  
- bitsandbytes (quantization)  

> **LÆ°u Ã½**: Project dÃ¹ng cho **educational purposes**. Má»™t sá»‘ models yÃªu cáº§u token tá»« HuggingFace hoáº·c tuÃ¢n thá»§ license riÃªng.
---

## ğŸ”— GitHub cá»§a tÃ¡c giáº£

<div align="center">

<img src="https://capsule-render.vercel.app/api?type=waving&color=gradient&height=120&section=header"/>

<p align="center">
  <a href="https://github.com/Kietnehi">
    <img src="https://github.com/Kietnehi.png" width="140" height="140" style="border-radius: 50%; border: 4px solid #A371F7;" alt="Avatar TrÆ°Æ¡ng PhÃº Kiá»‡t"/>
  </a>
</p>

<h3>ğŸš€ TrÆ°Æ¡ng PhÃº Kiá»‡t</h3>

<a href="https://github.com/Kietnehi">
  <img src="https://readme-typing-svg.herokuapp.com?font=Fira+Code&pause=1000&color=236AD3&background=00000000&center=true&vCenter=true&width=435&lines=Student+@+Sai+Gon+University;Fullstack+Dev+%26+AI+Researcher;Building+RAG+%26+Docker+Systems" alt="Typing SVG" />
</a>

<br/><br/>

<p align="center">
  <img src="https://img.shields.io/badge/SGU-Sai_Gon_University-0056D2?style=flat-square&logo=google-scholar&logoColor=white" alt="SGU"/>
  <img src="https://img.shields.io/badge/Base-Ho_Chi_Minh_City-FF4B4B?style=flat-square&logo=google-maps&logoColor=white" alt="HCMC"/>
</p>

<h3>ğŸ›  Tech Stack</h3>
<p align="center">
  <a href="https://skillicons.dev">
    <img src="https://skillicons.dev/icons?i=docker,python,react,nodejs,mongodb,git,fastapi,pytorch&theme=light" alt="My Skills"/>
  </a>
</p>

<br/>

<h3>ğŸŒŸ Dá»± Ã¡n: RAG Multi-LLM System</h3>
<p align="center">
  <a href="https://github.com/Kietnehi/RAG">
    <img src="https://img.shields.io/github/stars/Kietnehi/RAG?style=for-the-badge&color=yellow" alt="Stars"/>
    <img src="https://img.shields.io/github/forks/Kietnehi/RAG?style=for-the-badge&color=orange" alt="Forks"/>
    <img src="https://img.shields.io/github/issues/Kietnehi/RAG?style=for-the-badge&color=red" alt="Issues"/>
  </a>
</p>
<!-- Quote Ä‘á»™ng -->
<p align="center">
  <img src="https://quotes-github-readme.vercel.app/api?type=horizontal&theme=dark" alt="Daily Quote"/>
</p>
<p align="center">
  <i>Cáº£m Æ¡n báº¡n Ä‘Ã£ ghÃ© thÄƒm! Äá»«ng quÃªn nháº¥n <b>â­ï¸ Star</b> Ä‘á»ƒ á»§ng há»™ mÃ¬nh nhÃ©.</i>
</p>

<img src="https://capsule-render.vercel.app/api?type=waving&color=gradient&height=80&section=footer"/>

</div>