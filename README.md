<div align="center">

# ğŸ¤– RAG Multi-LLM System (Quantized 8B Models)
**Há»‡ thá»‘ng RAG Ä‘a mÃ´ hÃ¬nh vá»›i kháº£ nÄƒng truy xuáº¥t tri thá»©c vÃ  tÃ¬m kiáº¿m Web thá»i gian thá»±c.**

<p align="center">
  <img src="image/pipeline.jpg" alt="RAG Pipeline" width="800"/>
</p>

<p align="center"><i>Overall pipeline of the RAG Multi-LLM System</i></p>


![GitHub repo size](https://img.shields.io/github/repo-size/Kietnehi/RAG?style=for-the-badge&color=blueviolet)
![GitHub last commit](https://img.shields.io/github/last-commit/Kietnehi/RAG?style=for-the-badge&color=brightgreen)
![GitHub license](https://img.shields.io/github/license/Kietnehi/RAG?style=for-the-badge&color=blue)
![GitHub issues](https://img.shields.io/github/issues/Kietnehi/RAG?style=for-the-badge&color=red)

---

### ğŸš€ Core Framework & Backend
![Python](https://img.shields.io/badge/Python_3.9+-3776AB?style=for-the-badge&logo=python&logoColor=white)
![FastAPI](https://img.shields.io/badge/FastAPI-009688?style=for-the-badge&logo=fastapi&logoColor=white)
![LangChain](https://img.shields.io/badge/LangChain-1C3C3C?style=for-the-badge&logo=langchain&logoColor=white)
![PyTorch](https://img.shields.io/badge/PyTorch-EE4C2C?style=for-the-badge&logo=pytorch&logoColor=white)
![Nginx](https://img.shields.io/badge/Nginx-009639?style=for-the-badge&logo=nginx&logoColor=white)

### ğŸ§  LLM & Vision Intelligence
![Google Gemini](https://img.shields.io/badge/Gemini_2.0_Flash-4285F4?style=for-the-badge&logo=googlegemini&logoColor=white)
![Meta Llama](https://img.shields.io/badge/Llama_2_8B-0467DF?style=for-the-badge&logo=meta&logoColor=white)
![Mistral AI](https://img.shields.io/badge/Mistral_7B-000000?style=for-the-badge)
![Microsoft Phi](https://img.shields.io/badge/Microsoft_Phi-0078D4?style=for-the-badge&logo=microsoft&logoColor=white)
![HuggingFace](https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-FFD21E?style=for-the-badge&color=gray)

### ğŸ“š RAG & Data Infrastructure
![ChromaDB](https://img.shields.io/badge/Vector_DB-ChromaDB-3178C6?style=for-the-badge)
![Google Search](https://img.shields.io/badge/Google_Search-Grounding-4285F4?style=for-the-badge&logo=google&logoColor=white)
![Vision AI](https://img.shields.io/badge/Vision_AI-BLIP-orange?style=for-the-badge)
![Quantization](https://img.shields.io/badge/Quantization-4bit/8bit-green?style=for-the-badge)

### ğŸ³ Deployment & DevOps
![Docker](https://img.shields.io/badge/Docker_Compose-2496ED?style=for-the-badge&logo=docker&logoColor=white)
![GPU](https://img.shields.io/badge/NVIDIA_GPU-Supported-76B900?style=for-the-badge&logo=nvidia&logoColor=white)
![Ubuntu](https://img.shields.io/badge/Ubuntu-E94333?style=for-the-badge&logo=ubuntu&logoColor=white)

---
</div>

> ğŸš€ **RAG Multi-LLM System** lÃ  má»™t há»‡ thá»‘ng **Retrieval-Augmented Generation (RAG)** hoÃ n chá»‰nh, há»— trá»£ **nhiá»u mÃ´ hÃ¬nh LLM quantized (4-bit / 8-bit)**, cÃ³ giao diá»‡n web, vector database vÃ  triá»ƒn khai dá»… dÃ ng báº±ng Docker.

> ğŸ”— **[GitHub Repository chÃ­nh thá»©c](https://github.com/Kietnehi/RAG)**


---

<p align="center">
  <img src="output.gif" width="100%" alt="Intro GIF" />
</p>


## ğŸ“Œ Giá»›i thiá»‡u dá»± Ã¡n

Dá»± Ã¡n **RAG Multi-LLM System** Ä‘Æ°á»£c xÃ¢y dá»±ng nháº±m má»¥c tiÃªu:

- ğŸ§  NghiÃªn cá»©u & triá»ƒn khai **Retrieval-Augmented Generation (RAG)** trong thá»±c táº¿
- âš¡ Cháº¡y **LLM 7Bâ€“8B** trÃªn mÃ¡y cáº¥u hÃ¬nh háº¡n cháº¿ báº±ng **quantization**
- ğŸŒ Cung cáº¥p **Web UI trá»±c quan** cho ngÆ°á»i dÃ¹ng cuá»‘i
- ğŸ³ Há»— trá»£ **Docker / GPU / CPU**
- ğŸ“š PhÃ¹ há»£p cho **educational, research, demo & portfolio**

---

## ğŸ§  AI â€“ Deep Learning â€“ RAG Overview

<table align="center">
  <tr>
    <td align="center" width="50%">
      <img src="image/readme/AI.jpg" width="100%" alt="AI Overview"><br>
      <b>Artificial Intelligence (AI)</b><br>
      <sub>Tá»•ng quan trÃ­ tuá»‡ nhÃ¢n táº¡o</sub>
    </td>
    <td align="center" width="50%">
      <img src="image/readme/deeplearning.jpg" width="100%" alt="Deep Learning"><br>
      <b>Deep Learning</b><br>
      <sub>Ná»n táº£ng cho LLM</sub>
    </td>
  </tr>
  <tr>
    <td align="center">
      <img src="image/readme/docx.jpg" width="100%" alt="RAG Documents"><br>
      <b>RAG Input Documents</b><br>
      <sub>PDF, DOCX, TXT</sub>
    </td>
    <td align="center">
      <img src="image/readme/rag_pipeline.jpg" width="100%" alt="RAG Pipeline"><br>
      <b>RAG Pipeline</b><br>
      <sub>Retrieve â†’ Context â†’ Generate</sub>
    </td>
  </tr>
</table>

---
## ğŸ³ Triá»ƒn khai Docker & Demo Giao Diá»‡n Web

> Minh há»a cÃ¡c Docker containers, Docker images vÃ  giao diá»‡n web cá»§a há»‡ thá»‘ng RAG Multi-LLM

### ğŸ“¦ CÃ¡c Docker Containers Ä‘ang cháº¡y

<p align="center">
  <img src="image/docker_container.png" width="90%" alt="Docker Containers">
</p>

<sub align="center">
Danh sÃ¡ch cÃ¡c container: frontend, backend (FastAPI), vector database
</sub>

---

### ğŸ§± Docker Images

#### ğŸ”¹ Docker Image â€“ Frontend

<p align="center">
  <img src="image/docker_image_frontend.png" width="80%" alt="Docker Image Frontend">
</p>

<sub align="center">
Image cho giao diá»‡n Web UI (HTML / CSS / JavaScript + Nginx)
</sub>

#### ğŸ”¹ Docker Image â€“ Backend

<p align="center">
  <img src="image/docker_image_backend.png" width="80%" alt="Docker Image Backend">
</p>

<sub align="center">
Image cho Backend FastAPI + LLM + RAG Engine
</sub>

---

### ğŸŒ Giao diá»‡n Web (Web UI)

<p align="center">
  <img src="image/frontend.png" width="90%" alt="Web UI Chat">
</p>

<sub align="center">
Giao diá»‡n chat RAG: upload tÃ i liá»‡u, chá»n mÃ´ hÃ¬nh, streaming cÃ¢u tráº£ lá»i
</sub>

**Demo Run - RAG Mode**

<p align="center">
  <img src="image/demo_run_rag.png" width="90%" alt="Demo Run RAG">
</p>

<sub align="center">
áº¢nh minh há»a quÃ¡ trÃ¬nh cháº¡y RAG (upload tÃ i liá»‡u vÃ  pháº£n há»“i tá»« model).
</sub>

---

### âœ¨ Gemini API vá»›i Google Search Tool

<p align="center">
  <img src="image/demo_app.png" width="90%" alt="Demo Gemini API with Google Search">
</p>

<sub align="center">
ğŸ”¥ TÃ­nh nÄƒng má»›i: Sá»­ dá»¥ng Gemini API vá»›i Google Search Ä‘á»ƒ tÃ¬m kiáº¿m thÃ´ng tin real-time tá»« web
</sub>

**TÃ­nh nÄƒng ná»•i báº­t:**
- ğŸŒ **Real-time Information**: Truy váº¥n thÃ´ng tin cáº­p nháº­t nháº¥t tá»« Google Search
- ğŸ” **Google Search Grounding**: Gemini tá»± Ä‘á»™ng tÃ¬m kiáº¿m vÃ  tá»•ng há»£p thÃ´ng tin tá»« nhiá»u nguá»“n
- ğŸ¯ **Accurate & Updated**: CÃ¢u tráº£ lá»i chÃ­nh xÃ¡c dá»±a trÃªn dá»¯ liá»‡u má»›i nháº¥t
- ğŸ” **Secure API Key**: NgÆ°á»i dÃ¹ng tá»± quáº£n lÃ½ API key cá»§a mÃ¬nh
- âš¡ **Fast Response**: Pháº£n há»“i nhanh chÃ³ng tá»« Gemini models

---

## âœ¨ TÃ­nh nÄƒng

- ğŸ§  **Há»— trá»£ nhiá»u LLM models 8B** (quantized vá»›i 4-bit/8-bit)
  - Meta Llama 2 7B
  - Mistral 7B Instruct
  - Google Gemma 7B
  - Microsoft Phi-2
  - TinyLlama 1.1B

- ğŸ“š **RAG vá»›i Vector Database**
  - ChromaDB cho vector storage
  - Sentence transformers cho embeddings
  - Há»— trá»£ PDF, DOCX, TXT

- âœ¨ **Gemini API vá»›i Google Search (NEW!)**
  - **Real-time Search**: TÃ¬m kiáº¿m thÃ´ng tin cáº­p nháº­t tá»« Google
  - **Google Search Grounding**: Tá»± Ä‘á»™ng tÃ¬m kiáº¿m vÃ  trÃ­ch xuáº¥t thÃ´ng tin tá»« web
  - **Dual Mode**: Chuyá»ƒn Ä‘á»•i linh hoáº¡t giá»¯a RAG local vÃ  Gemini API
  - **Multiple Models**: Há»— trá»£ Gemini 2.0 Flash, Gemini 2.5 Flash, Gemini 1.5 Pro
  - **User API Key**: NgÆ°á»i dÃ¹ng tá»± nháº­p API key, báº£o máº­t vÃ  linh hoáº¡t

- ğŸ–¼ï¸ **BLIP - Vision AI cho xá»­ lÃ½ hÃ¬nh áº£nh**
  - **Visual Question Answering (VQA)**: Tráº£ lá»i cÃ¢u há»i dá»±a trÃªn ná»™i dung hÃ¬nh áº£nh
  - **Image Captioning**: Tá»± Ä‘á»™ng táº¡o mÃ´ táº£ chi tiáº¿t cho hÃ¬nh áº£nh
  - TÃ­ch há»£p vá»›i RAG Ä‘á»ƒ káº¿t há»£p thÃ´ng tin tá»« vÄƒn báº£n vÃ  hÃ¬nh áº£nh
  - Upload hÃ¬nh áº£nh vÃ  chat vá» ná»™i dung áº£nh

- ğŸ¨ **Web Interface hiá»‡n Ä‘áº¡i**
  - Chat interface vá»›i streaming
  - Upload vÃ  quáº£n lÃ½ documents
  - Upload vÃ  xá»­ lÃ½ hÃ¬nh áº£nh vá»›i BLIP
  - Switch giá»¯a cÃ¡c models
  - Äiá»u chá»‰nh temperature, max tokens

- ğŸ³ **Docker support**
  - Docker Compose cho deployment dá»… dÃ ng
  - GPU support cho inference nhanh
  - Persistent storage cho documents

## ğŸ—ï¸ Kiáº¿n trÃºc

```
RAG MINI/
â”œâ”€â”€ backend/                 # FastAPI backend
â”‚   â””â”€â”€ app/
â”‚       â”œâ”€â”€ main.py         # API endpoints
â”‚       â”œâ”€â”€ models/
â”‚       â”‚   â”œâ”€â”€ llm_manager.py      # Quáº£n lÃ½ LLM models
â”‚       â”‚   â”œâ”€â”€ rag_engine.py       # RAG logic
â”‚       â”‚   â””â”€â”€ blip_processor.py   # BLIP Vision AI
â”‚       â””â”€â”€ utils/
â”‚           â””â”€â”€ document_processor.py
â”œâ”€â”€ frontend/               # Web UI
â”‚   â”œâ”€â”€ index.html
â”‚   â”œâ”€â”€ style.css
â”‚   â””â”€â”€ script.js
â”œâ”€â”€ Dockerfile             # Backend container
â”œâ”€â”€ Dockerfile.frontend    # Frontend container
â”œâ”€â”€ docker-compose.yml     # Orchestration
â”œâ”€â”€ nginx.conf            # Nginx config
â””â”€â”€ requirements.txt      # Python dependencies
```

## ğŸš€ CÃ i Ä‘áº·t vÃ  Cháº¡y

### YÃªu cáº§u

- Docker & Docker Compose
- NVIDIA GPU (khuyáº¿n nghá»‹, nhÆ°ng cÃ³ thá»ƒ cháº¡y trÃªn CPU)
- 8GB RAM trá»Ÿ lÃªn
- 10GB disk space cho models

### CÃ¡ch 1: Docker Compose (Khuyáº¿n nghá»‹)

1. **Clone hoáº·c táº£i project**

2. **Cáº¥u hÃ¬nh mÃ´i trÆ°á»ng** (optional)
```bash
cp .env.example .env
# Edit .env Ä‘á»ƒ thay Ä‘á»•i model máº·c Ä‘á»‹nh vÃ  settings
```

3. **Build vÃ  cháº¡y**
```bash
docker-compose up --build
```

4. **Truy cáº­p á»©ng dá»¥ng**
- Frontend: http://localhost
- Backend API: http://localhost:8000
- API Docs: http://localhost:8000/docs

### CÃ¡ch 2: Local Development

1. **CÃ i Ä‘áº·t dependencies**
```bash
pip install -r requirements.txt
```

2. **Táº¡o file .env**
```bash
cp .env.example .env
```

3. **Cháº¡y backend**
```bash
cd backend
uvicorn app.main:app --host 0.0.0.0 --port 8000 --reload
```

4. **Cháº¡y frontend**
```bash
# Má»Ÿ frontend/index.html trong browser
# Hoáº·c dÃ¹ng simple HTTP server:
cd frontend
python -m http.server 3000
```

## ğŸ® Sá»­ dá»¥ng

### 1. Chá»n Query Mode

#### ğŸ¤– RAG Mode (Local LLM)
- Sá»­ dá»¥ng LLM models local vá»›i tÃ i liá»‡u Ä‘Ã£ upload
- PhÃ¹ há»£p cho queries vá» tÃ i liá»‡u riÃªng tÆ°
- KhÃ´ng cáº§n API key, hoÃ n toÃ n offline

#### âœ¨ Gemini API Mode (Google Search)
- TÃ¬m kiáº¿m thÃ´ng tin real-time tá»« Google
- Tráº£ lá»i cÃ¡c cÃ¢u há»i vá» sá»± kiá»‡n má»›i nháº¥t
- **YÃªu cáº§u**: Gemini API Key (láº¥y miá»…n phÃ­ táº¡i [Google AI Studio](https://aistudio.google.com/apikey))

**CÃ¡ch sá»­ dá»¥ng Gemini API:**
1. Chá»n **Mode**: "âœ¨ Gemini API (Google Search)"
2. Nháº­p **Gemini API Key** vÃ o Ã´ input
3. Báº­t/táº¯t **"Sá»­ dá»¥ng Google Search"** (khuyáº¿n nghá»‹: báº­t)
4. Chá»n **Model**: Gemini 2.0 Flash (khuyáº¿n nghá»‹) / Gemini 2.5 Flash / Gemini 1.5 Pro
5. Nháº­p cÃ¢u há»i vÃ  nháº­n káº¿t quáº£ tá»« Google Search!

**VÃ­ dá»¥ cÃ¢u há»i phÃ¹ há»£p vá»›i Gemini API:**
- "Ai vÃ´ Ä‘á»‹ch Euro 2024?"
- "GiÃ¡ Bitcoin hÃ´m nay?"
- "Tin tá»©c cÃ´ng nghá»‡ AI má»›i nháº¥t?"
- "Thá»i tiáº¿t HÃ  Ná»™i hÃ´m nay?"

### 2. Upload Documents (RAG Mode)

1. Click vÃ o **"ğŸ“ Upload Documents"** trong sidebar
2. Chá»n file (PDF, DOCX, TXT)
3. Click **Upload**
4. Documents sáº½ Ä‘Æ°á»£c xá»­ lÃ½ vÃ  lÆ°u vÃ o vector database

### 3. Upload vÃ  xá»­ lÃ½ hÃ¬nh áº£nh vá»›i BLIP

1. Click vÃ o **"ğŸ–¼ï¸ Upload Image"** trong sidebar
2. Chá»n hÃ¬nh áº£nh (JPG, PNG)
3. Chá»n cháº¿ Ä‘á»™ xá»­ lÃ½:
   - **VQA (Visual Question Answering)**: Há»i vá» ná»™i dung hÃ¬nh áº£nh
   - **Caption**: Tá»± Ä‘á»™ng táº¡o mÃ´ táº£ hÃ¬nh áº£nh
4. Nháº­p cÃ¢u há»i vá» hÃ¬nh áº£nh (náº¿u chá»n VQA)
5. Há»‡ thá»‘ng sáº½ phÃ¢n tÃ­ch vÃ  tráº£ lá»i dá»±a trÃªn hÃ¬nh áº£nh

### 4. Chat vá»›i RAG hoáº·c Gemini

**RAG Mode:**
1. Nháº­p cÃ¢u há»i vÃ o chat input
2. Báº­t **"Sá»­ dá»¥ng RAG"** Ä‘á»ƒ query tá»« documents
3. Táº¯t RAG Ä‘á»ƒ chat trá»±c tiáº¿p vá»›i LLM
4. Káº¿t há»£p vá»›i hÃ¬nh áº£nh Ä‘Ã£ upload Ä‘á»ƒ cÃ³ cÃ¢u tráº£ lá»i Ä‘áº§y Ä‘á»§ hÆ¡n
5. Click **Gá»­i** hoáº·c nháº¥n Enter

**Gemini Mode:**
1. Äáº£m báº£o Ä‘Ã£ nháº­p API key
2. Nháº­p cÃ¢u há»i (cÃ³ thá»ƒ vá» thÃ´ng tin real-time)
3. Click **Gá»­i** - Gemini sáº½ tá»± Ä‘á»™ng search Google vÃ  tráº£ lá»i
4. Káº¿t quáº£ sáº½ hiá»ƒn thá»‹ vá»›i badge "âœ¨ Powered by Gemini with Google Search"

### 5. Switch Models (RAG Mode)

1. Chá»n model tá»« dropdown **"Model"**
2. Click **"Load Model"**
3. Äá»£i model load (cÃ³ thá»ƒ máº¥t 1-2 phÃºt)

### 6. Äiá»u chá»‰nh Parameters

- **Temperature**: 0-1 (creativity)
- **Max Tokens**: 128-2048 (response length)
- **Image Mode**: VQA hoáº·c Caption khi upload hÃ¬nh áº£nh

## ğŸ”§ Cáº¥u hÃ¬nh

### Environment Variables (.env)

```env
# Model Configuration
MODEL_NAME=TinyLlama/TinyLlama-1.1B-Chat-v1.0
LOAD_IN_8BIT=true
LOAD_IN_4BIT=false

# Generation Settings
MAX_NEW_TOKENS=512
TEMPERATURE=0.7

# Vector DB Settings
EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2
CHUNK_SIZE=500
CHUNK_OVERLAP=50
```

### Chá»n Model khÃ¡c

Sá»­a `MODEL_NAME` trong `.env`:

```env
# Llama 2 7B (yÃªu cáº§u HuggingFace token)
MODEL_NAME=meta-llama/Llama-2-7b-chat-hf

# Mistral 7B
MODEL_NAME=mistralai/Mistral-7B-Instruct-v0.2

# Gemma 7B (yÃªu cáº§u Google token)
MODEL_NAME=google/gemma-7b-it

# Phi-2 (nhá», nhanh)
MODEL_NAME=microsoft/phi-2

# TinyLlama (nhá» nháº¥t, cho testing)
MODEL_NAME=TinyLlama/TinyLlama-1.1B-Chat-v1.0
```

### Quantization Options

```env
# 8-bit quantization (tiáº¿t kiá»‡m ~50% VRAM)
LOAD_IN_8BIT=true
LOAD_IN_4BIT=false

# 4-bit quantization (tiáº¿t kiá»‡m ~75% VRAM)
LOAD_IN_8BIT=false
LOAD_IN_4BIT=true
```

## ğŸ“Š API Endpoints

### Health Check
```bash
GET /health
```

### List Models
```bash
GET /models
```

### Load Model
```bash
POST /models/load?model_name=<model_name>
```

### Upload Document
```bash
POST /upload
Content-Type: multipart/form-data
```

### Upload Image (BLIP)
```bash
POST /upload-image
Content-Type: multipart/form-data
```

### Query (RAG + BLIP)

```bash
POST /query
Content-Type: application/json

{
  "query": "Your question here",
  "use_rag": true,
  "max_tokens": 512,
  "temperature": 0.7,
  "image_base64": "<base64_encoded_image>",  // Optional
  "image_mode": "vqa"  // "vqa" hoáº·c "caption"
}
```

### Clear Documents
```bash
DELETE /documents
```

### Query vá»›i Gemini API

```bash
POST /query/gemini
Content-Type: application/json

{
  "query": "Who won Euro 2024?",
  "api_key": "your-gemini-api-key",
  "use_grounding": true,
  "model": "gemini-2.0-flash-exp",
  "max_tokens": 512,
  "temperature": 0.7
}
```

### Query vá»›i Gemini API (Streaming)

```bash
POST /query/gemini/stream
Content-Type: application/json

{
  "query": "Latest AI news",
  "api_key": "your-gemini-api-key",
  "use_grounding": true,
  "model": "gemini-2.0-flash-exp",
  "max_tokens": 512,
  "temperature": 0.7
}
```

**Láº¥y Gemini API Key miá»…n phÃ­:**
- Truy cáº­p: https://aistudio.google.com/apikey
- ÄÄƒng nháº­p vá»›i Google account
- Táº¡o API key má»›i
- Copy vÃ  sá»­ dá»¥ng trong á»©ng dá»¥ng

## ğŸ› Troubleshooting

### Model khÃ´ng load Ä‘Æ°á»£c

1. Kiá»ƒm tra RAM/VRAM Ä‘á»§ khÃ´ng
2. Thá»­ model nhá» hÆ¡n (TinyLlama)
3. Enable quantization (8-bit hoáº·c 4-bit)

### Out of Memory

1. TÄƒng Docker memory limit
2. Sá»­ dá»¥ng 4-bit quantization
3. Chá»n model nhá» hÆ¡n

### Docker khÃ´ng start

```bash
# Xem logs
docker-compose logs -f

# Restart
docker-compose down
docker-compose up --build
```

### GPU khÃ´ng Ä‘Æ°á»£c detect

1. CÃ i Ä‘áº·t NVIDIA Docker runtime
2. Kiá»ƒm tra: `docker run --gpus all nvidia/cuda:11.8.0-base-ubuntu22.04 nvidia-smi`
3. Náº¿u khÃ´ng cÃ³ GPU, xÃ³a pháº§n `deploy.resources` trong docker-compose.yml

## ğŸ¯ Performance Tips

1. **Sá»­ dá»¥ng GPU**: Nhanh hÆ¡n 10-20x so vá»›i CPU
2. **Quantization**: Giáº£m VRAM, tÄƒng tá»‘c Ä‘á»™
3. **Cache models**: Models Ä‘Æ°á»£c cache sau láº§n Ä‘áº§u
4. **Chunking**: Adjust `CHUNK_SIZE` phÃ¹ há»£p vá»›i documents
## ğŸ“ TODO / Improvements

- [ ] ThÃªm **authentication**
- [ ] Multi-user support
- [ ] Conversation history
- [ ] Advanced RAG strategies (HyDE, Multi-query)
- [ ] Model comparison mode
- [ ] Export chat history
- [ ] Support thÃªm file formats (CSV, Excel, etc.)

---

## ğŸ¤ Contributing

ChÃºng tÃ´i hoan nghÃªnh má»i Ä‘Ã³ng gÃ³p!  
Vui lÃ²ng táº¡o **issue** hoáº·c **pull request** trÃªn GitHub.

---

## ğŸ“„ License

MIT License

---

## ğŸ™ Credits

- FastAPI  
- Transformers (HuggingFace)  
- LangChain  
- ChromaDB  
- bitsandbytes (quantization)  
- BLIP (Salesforce) - Vision AI  
- Pillow - Image processing  
- **Google Gemini API** - Real-time search vá»›i Google Search grounding  
- **Google AI Studio** - API key management  

> **LÆ°u Ã½**: Project dÃ¹ng cho **educational purposes**. Má»™t sá»‘ models yÃªu cáº§u token tá»« HuggingFace hoáº·c tuÃ¢n thá»§ license riÃªng.
---

## ğŸ”— GitHub cá»§a tÃ¡c giáº£

<div align="center">

<img src="https://capsule-render.vercel.app/api?type=waving&color=gradient&height=120&section=header"/>

<p align="center">
  <a href="https://github.com/Kietnehi">
    <img src="https://github.com/Kietnehi.png" width="140" height="140" style="border-radius: 50%; border: 4px solid #A371F7;" alt="Avatar TrÆ°Æ¡ng PhÃº Kiá»‡t"/>
  </a>
</p>

<h3>ğŸš€ TrÆ°Æ¡ng PhÃº Kiá»‡t</h3>

<a href="https://github.com/Kietnehi">
  <img src="https://readme-typing-svg.herokuapp.com?font=Fira+Code&pause=1000&color=236AD3&background=00000000&center=true&vCenter=true&width=435&lines=Student+@+Sai+Gon+University;Fullstack+Dev+%26+AI+Researcher;Building+RAG+%26+Docker+Systems" alt="Typing SVG" />
</a>

<br/><br/>

<p align="center">
  <img src="https://img.shields.io/badge/SGU-Sai_Gon_University-0056D2?style=flat-square&logo=google-scholar&logoColor=white" alt="SGU"/>
  <img src="https://img.shields.io/badge/Base-Ho_Chi_Minh_City-FF4B4B?style=flat-square&logo=google-maps&logoColor=white" alt="HCMC"/>
</p>

<h3>ğŸ›  Tech Stack</h3>
<p align="center">
  <a href="https://skillicons.dev">
    <img src="https://skillicons.dev/icons?i=docker,python,react,nodejs,mongodb,git,fastapi,pytorch&theme=light" alt="My Skills"/>
  </a>
</p>

<br/>

<h3>ğŸŒŸ Dá»± Ã¡n: RAG Multi-LLM System</h3>
<p align="center">
  <a href="https://github.com/Kietnehi/RAG">
    <img src="https://img.shields.io/github/stars/Kietnehi/RAG?style=for-the-badge&color=yellow" alt="Stars"/>
    <img src="https://img.shields.io/github/forks/Kietnehi/RAG?style=for-the-badge&color=orange" alt="Forks"/>
    <img src="https://img.shields.io/github/issues/Kietnehi/RAG?style=for-the-badge&color=red" alt="Issues"/>
  </a>
</p>
<!-- Quote Ä‘á»™ng -->
<p align="center">
  <img src="https://quotes-github-readme.vercel.app/api?type=horizontal&theme=dark" alt="Daily Quote"/>
</p>
<p align="center">
  <i>Cáº£m Æ¡n báº¡n Ä‘Ã£ ghÃ© thÄƒm! Äá»«ng quÃªn nháº¥n <b>â­ï¸ Star</b> Ä‘á»ƒ á»§ng há»™ mÃ¬nh nhÃ©.</i>
</p>

<img src="https://capsule-render.vercel.app/api?type=waving&color=gradient&height=80&section=footer"/>

</div>